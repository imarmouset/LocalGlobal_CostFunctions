{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Local network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- self-supervised learning on MNIST\n",
    "\n",
    "- Apply feedback alignment to both layers in the PV class (fc1 and fc2), not just the second one (fc2)? \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/irismarmouset-delataille/mambaforge/envs/localglobal/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Users/irismarmouset-delataille/mambaforge/envs/localglobal/lib/python3.11/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <E03EDA44-89AE-3115-9796-62BA9E0E2EDE> /Users/irismarmouset-delataille/mambaforge/envs/localglobal/lib/python3.11/site-packages/torchvision/image.so\n",
      "  Expected in:     <E943EB88-577E-37A4-93E1-5DAFE97B5744> /Users/irismarmouset-delataille/mambaforge/envs/localglobal/lib/python3.11/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1161f2a10>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 60000\n",
      "Test dataset size: 10000\n"
     ]
    }
   ],
   "source": [
    "from dataset import get_mnist_dataset\n",
    "working_directory = os.getcwd()\n",
    "data_dir = os.path.join(working_directory, './dataset')\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "\n",
    "train_data_loader, test_data_loader = get_mnist_dataset(data_dir, batch_size_train=batch_size_train, batch_size_test=batch_size_test)\n",
    "\n",
    "print('Train dataset size: {}'.format(len(train_data_loader.dataset)))\n",
    "print('Test dataset size: {}'.format(len(test_data_loader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LocalNetwork(\n",
      "  (PV): PV(\n",
      "    (flatten): Flatten()\n",
      "    (fc1): Linear(in_features=784, out_features=784, bias=True)\n",
      "    (activation): Sigmoid()\n",
      "    (fc2): Linear(in_features=784, out_features=128, bias=True)\n",
      "  )\n",
      "  (Pyr): Pyr(\n",
      "    (flatten): Flatten()\n",
      "    (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
      "    (activation): Sigmoid()\n",
      "  )\n",
      "  (Decoder): Decoder(\n",
      "    (fc1): Linear(in_features=128, out_features=784, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from modules.network import LocalNetwork\n",
    "\n",
    "lr = 0.001\n",
    "\n",
    "model = LocalNetwork(input_dim=784, latent_dim=128)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training & testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "train_losses = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_counter = [i*len(train_data_loader.dataset) for i in range(num_epochs + 1)]\n",
    "\n",
    "def train(epoch, dataloader):\n",
    "    model.train()\n",
    "    for batch in dataloader:\n",
    "        inputs, _ = batch  \n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        _, _, _, recon = model(inputs, inputs)  # same inputs for both PV and pyramidal cells\n",
    "        inputs = inputs.view(-1, 784)\n",
    "        loss = criterion(recon, inputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print('Epoch: {} Loss: {:.6f}'.format(epoch, loss.item()))\n",
    "\n",
    "def test(epoch, dataloader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            inputs, _ = batch\n",
    "            _, _, _, recon = model(inputs, inputs)\n",
    "            inputs = inputs.view(-1, 784)\n",
    "            test_loss += criterion(recon, inputs).item()\n",
    "    test_loss /= len(dataloader.dataset)\n",
    "    test_losses.append(test_loss)\n",
    "    print('\\n Epoch: {} Test set: Avg. loss: {:.4f}\\n'.format(epoch, test_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In practice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.0011\n",
      "\n",
      "Epoch: 1 Loss: 0.123183\n",
      "\n",
      "Test set: Avg. loss: 0.0001\n",
      "\n",
      "Epoch: 2 Loss: 0.092175\n",
      "\n",
      "Test set: Avg. loss: 0.0001\n",
      "\n",
      "Epoch: 3 Loss: 0.084952\n",
      "\n",
      "Test set: Avg. loss: 0.0001\n",
      "\n",
      "Epoch: 4 Loss: 0.061202\n",
      "\n",
      "Test set: Avg. loss: 0.0001\n",
      "\n",
      "Epoch: 5 Loss: 0.055561\n",
      "\n",
      "Test set: Avg. loss: 0.0001\n",
      "\n",
      "Epoch: 6 Loss: 0.056677\n",
      "\n",
      "Test set: Avg. loss: 0.0001\n",
      "\n",
      "Epoch: 7 Loss: 0.067480\n",
      "\n",
      "Test set: Avg. loss: 0.0001\n",
      "\n",
      "Epoch: 8 Loss: 0.056903\n",
      "\n",
      "Test set: Avg. loss: 0.0001\n",
      "\n",
      "Epoch: 9 Loss: 0.052013\n",
      "\n",
      "Test set: Avg. loss: 0.0001\n",
      "\n",
      "Epoch: 10 Loss: 0.048799\n",
      "\n",
      "Test set: Avg. loss: 0.0001\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test(test_data_loader)\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "  train(epoch, train_data_loader)\n",
    "  test(test_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
